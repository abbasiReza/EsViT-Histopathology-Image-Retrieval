{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7252,"status":"ok","timestamp":1649254724473,"user":{"displayName":"reza abbasi","userId":"16461171515024221393"},"user_tz":-270},"id":"9LfWvzTlSFE_","outputId":"d5aac62f-868a-437d-af64-7263434ca532"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content\n","/content/drive/MyDrive/models/esvit-main\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!pwd \n","%cd drive/MyDrive/models/esvit-main/"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13356,"status":"ok","timestamp":1649254737817,"user":{"displayName":"reza abbasi","userId":"16461171515024221393"},"user_tz":-270},"id":"6zKwmKgKSFyz","outputId":"5bc72834-db6f-4e9f-e371-9f6cf1bb097e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Apr  6 14:18:42 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Requirement already satisfied: timm==0.4.9 in /usr/local/lib/python3.7/dist-packages (0.4.9)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm==0.4.9) (1.10.0+cu111)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm==0.4.9) (0.11.1+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm==0.4.9) (3.10.0.2)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.4.9) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.4.9) (1.21.5)\n","Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (0.1.8)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from yacs) (6.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (6.0)\n","Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.4.1)\n"]}],"source":["!nvidia-smi\n","!pip install timm==0.4.9\n","!pip install yacs\n","!pip install -U PyYAML\n","!pip install einops"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WhVl8OjuSGPA"},"outputs":[],"source":["# Modified by Chunyuan Li (chunyl@microsoft.com)\n","#\n","# Copyright (c) Facebook, Inc. and its affiliates.\n","# \n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","# \n","#     http://www.apache.org/licenses/LICENSE-2.0\n","# \n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\n","\n","import os\n","import argparse\n","\n","import torch\n","from torch import nn\n","import torch.distributed as dist\n","import torch.backends.cudnn as cudnn\n","from torchvision import datasets\n","from torchvision import transforms as pth_transforms\n","\n","from torchvision import models as torchvision_models\n","torchvision_archs = sorted(name for name in torchvision_models.__dict__\n","    if name.islower() and not name.startswith(\"__\")\n","    and callable(torchvision_models.__dict__[name]))\n","\n","import json\n","from pathlib import Path\n","import utils\n","import models.vision_transformer as vits\n","from models.vision_transformer import DINOHead\n","from models import build_model\n","\n","from config import config\n","from config import update_config\n","from config import save_config\n","\n","\n","def extract_feature_pipeline(args):\n","    # ============ preparing data ... ============\n","    transform = pth_transforms.Compose([\n","        pth_transforms.Resize(256, interpolation=3),\n","        pth_transforms.CenterCrop(224),\n","        pth_transforms.ToTensor(),\n","        pth_transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","    ])\n","\n"," \n","    if args.zip_mode:\n","        from datasets.zipdata import ZipData\n","\n","        datapath_train = os.path.join(args.data_path, 'train.zip')\n","        data_map_train = os.path.join(args.data_path, 'train_map.txt')\n","\n","        dataset_train = ZipData(\n","            datapath_train, data_map_train,\n","            transform\n","        )\n","\n","        datapath_val = os.path.join(args.data_path, 'val.zip')\n","        data_map_val = os.path.join(args.data_path, 'val_map.txt')\n","\n","        dataset_val = ZipData(\n","            datapath_val, data_map_val,\n","            transform\n","        )\n","\n","    else:\n","        dataset_train = ReturnIndexDataset(os.path.join(args.data_path, \"train\"), transform=transform)\n","        dataset_val = ReturnIndexDataset(os.path.join(args.data_path, \"val\"), transform=transform)\n","\n","    sampler = torch.utils.data.DistributedSampler(dataset_train, shuffle=False)\n","    data_loader_train = torch.utils.data.DataLoader(\n","        dataset_train,\n","        sampler=sampler,\n","        batch_size=args.batch_size_per_gpu,\n","        num_workers=args.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","    data_loader_val = torch.utils.data.DataLoader(\n","        dataset_val,\n","        batch_size=args.batch_size_per_gpu,\n","        num_workers=args.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","    print(f\"Data loaded with {len(dataset_train)} train and {len(dataset_val)} val imgs.\")\n","\n","    # ============ building network ... ============\n","\n","\n","    # if the network is a 4-stage vision transformer (i.e. swin)\n","    if 'swin' in args.arch :\n","        update_config(config, args)\n","        model = build_model(config, is_teacher=True)\n","\n","    # if the network is a 4-stage vision transformer (i.e. longformer)\n","    elif 'vil' in args.arch :\n","        update_config(config, args)\n","        model = build_model(config, is_teacher=True)\n","\n","    # if the network is a 4-stage vision transformer (i.e. CvT)\n","    elif 'cvt' in args.arch :\n","        update_config(config, args)\n","        model = build_model(config, is_teacher=True)\n","\n","    # if the network is a vision transformer (i.e. deit_tiny, deit_small, vit_base)\n","    elif args.arch in vits.__dict__.keys():\n","        model = vits.__dict__[args.arch](patch_size=args.patch_size, num_classes=0)\n","\n","\n","    print(f\"Model {args.arch} {args.patch_size}x{args.patch_size} built.\")\n","    model.cuda()\n","    utils.load_pretrained_weights(model, args.pretrained_weights, args.checkpoint_key, args.arch, args.patch_size)\n","    model.eval()\n","\n","    # ============ extract features ... ============\n","    print(\"Extracting features for train set...\")\n","    train_features = extract_features(model, data_loader_train)\n","    print(\"Extracting features for val set...\")\n","    test_features = extract_features(model, data_loader_val)\n","\n","    if utils.get_rank() == 0:\n","        train_features = nn.functional.normalize(train_features, dim=1, p=2)\n","        test_features = nn.functional.normalize(test_features, dim=1, p=2)\n","\n","    train_labels = torch.tensor([s[-1] for s in dataset_train.samples]).long()\n","    test_labels = torch.tensor([s[-1] for s in dataset_val.samples]).long()\n","    # save features and labels\n","    if args.dump_features and dist.get_rank() == 0:\n","        if not os.path.exists(args.dump_features):\n","            os.makedirs(args.dump_features)\n","        torch.save(train_features.cpu(), os.path.join(args.dump_features, \"trainfeat.pth\"))\n","        torch.save(test_features.cpu(), os.path.join(args.dump_features, \"testfeat.pth\"))\n","        torch.save(train_labels.cpu(), os.path.join(args.dump_features, \"trainlabels.pth\"))\n","        torch.save(test_labels.cpu(), os.path.join(args.dump_features, \"testlabels.pth\"))\n","    return train_features, test_features, train_labels, test_labels\n","\n","\n","@torch.no_grad()\n","def extract_features(model, data_loader):\n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    features = None\n","    for samples, index in metric_logger.log_every(data_loader, 10):\n","        samples = samples.cuda(non_blocking=True)\n","        index = index.cuda(non_blocking=True)\n","        feats = model(samples).clone()\n","\n","        # init storage feature matrix\n","        if dist.get_rank() == 0 and features is None:\n","            features = torch.zeros(len(data_loader.dataset), feats.shape[-1])\n","            if args.use_cuda:\n","                features = features.cuda(non_blocking=True)\n","            print(f\"Storing features into tensor of shape {features.shape}\")\n","\n","        # get indexes from all processes\n","        y_all = torch.empty(dist.get_world_size(), index.size(0), dtype=index.dtype, device=index.device)\n","        y_l = list(y_all.unbind(0))\n","        y_all_reduce = torch.distributed.all_gather(y_l, index, async_op=True)\n","        y_all_reduce.wait()\n","        index_all = torch.cat(y_l)\n","\n","        # share features between processes\n","        feats_all = torch.empty(\n","            dist.get_world_size(),\n","            feats.size(0),\n","            feats.size(1),\n","            dtype=feats.dtype,\n","            device=feats.device,\n","        )\n","        output_l = list(feats_all.unbind(0))\n","        output_all_reduce = torch.distributed.all_gather(output_l, feats, async_op=True)\n","        output_all_reduce.wait()\n","\n","        # update storage feature matrix\n","        if dist.get_rank() == 0:\n","            if args.use_cuda:\n","                features.index_copy_(0, index_all, torch.cat(output_l))\n","            else:\n","                features.index_copy_(0, index_all.cpu(), torch.cat(output_l).cpu())\n","    return features\n","\n","\n","@torch.no_grad()\n","def knn_classifier(train_features, train_labels, test_features, test_labels, k, T, num_classes=1000):\n","    top1, top5, total = 0.0, 0.0, 0\n","    train_features = train_features.t()\n","    num_test_images, num_chunks = test_labels.shape[0], 100\n","    imgs_per_chunk = num_test_images // num_chunks\n","    retrieval_one_hot = torch.zeros(k, num_classes).cuda()\n","    for idx in range(0, num_test_images, imgs_per_chunk):\n","        # get the features for test images\n","        features = test_features[\n","            idx : min((idx + imgs_per_chunk), num_test_images), :\n","        ]\n","        targets = test_labels[idx : min((idx + imgs_per_chunk), num_test_images)]\n","        batch_size = targets.shape[0]\n","\n","        # calculate the dot product and compute top-k neighbors\n","        similarity = torch.mm(features, train_features)\n","        distances, indices = similarity.topk(k, largest=True, sorted=True)\n","        candidates = train_labels.view(1, -1).expand(batch_size, -1)\n","        retrieved_neighbors = torch.gather(candidates, 1, indices)\n","\n","        retrieval_one_hot.resize_(batch_size * k, num_classes).zero_()\n","        retrieval_one_hot.scatter_(1, retrieved_neighbors.view(-1, 1), 1)\n","        distances_transform = distances.clone().div_(T).exp_()\n","        probs = torch.sum(\n","            torch.mul(\n","                retrieval_one_hot.view(batch_size, -1, num_classes),\n","                distances_transform.view(batch_size, -1, 1),\n","            ),\n","            1,\n","        )\n","        _, predictions = probs.sort(1, True)\n","\n","        # find the predictions that match the target\n","        correct = predictions.eq(targets.data.view(-1, 1))\n","        top1 = top1 + correct.narrow(1, 0, 1).sum().item()\n","        top5 = top5 + correct.narrow(1, 0, 5).sum().item()\n","        total += targets.size(0)\n","    top1 = top1 * 100.0 / total\n","    top5 = top5 * 100.0 / total\n","    return top1, top5\n","\n","\n","class ReturnIndexDataset(datasets.ImageFolder):\n","    def __getitem__(self, idx):\n","        img, lab = super(ReturnIndexDataset, self).__getitem__(idx)\n","        return img, idx\n","\n","\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser('Evaluation with weighted k-NN on ImageNet')\n","\n","    parser.add_argument('--cfg',\n","                        help='experiment configure file name',\n","                        type=str)\n","\n","    parser.add_argument('--arch', default='swin_small', type=str,\n","        choices=['cvt_tiny', 'swin_tiny','swin_small', 'swin_base', 'swin_large', 'swin', 'vil', 'vil_1281', 'vil_2262', 'deit_tiny', 'deit_small', 'vit_base'] + torchvision_archs,\n","        help=\"\"\"Name of architecture to train. For quick experiments with ViTs,\n","        we recommend using deit_tiny or deit_small.\"\"\")\n","\n","    parser.add_argument('--batch_size_per_gpu', default=128, type=int, help='Per-GPU batch-size')\n","    parser.add_argument('--nb_knn', default=[10, 20, 100, 200], nargs='+', type=int,\n","        help='Number of NN to use. 20 is usually working the best.')\n","    parser.add_argument('--temperature', default=0.07, type=float,\n","        help='Temperature used in the voting coefficient')\n","    parser.add_argument('--pretrained_weights', default='', type=str, help=\"Path to pretrained weights to evaluate.\")\n","    parser.add_argument('--use_cuda', default=True, type=utils.bool_flag,\n","        help=\"Should we store the features on GPU? We recommend setting this to False if you encounter OOM\")\n","    parser.add_argument('--patch_size', default=16, type=int, help='Patch resolution of the model.')\n","    parser.add_argument(\"--checkpoint_key\", default=\"teacher\", type=str,\n","        help='Key to use in the checkpoint (example: \"teacher\")')\n","    parser.add_argument('--dump_features', default=None,\n","        help='Path where to save computed features, empty for no saving')\n","    parser.add_argument('--load_features', default=None, help=\"\"\"If the features have\n","        already been computed, where to find them.\"\"\")\n","    parser.add_argument('--num_workers', default=10, type=int, help='Number of data loading workers per GPU.')\n","    parser.add_argument(\"--dist_url\", default=\"env://\", type=str, help=\"\"\"url used to set up\n","        distributed training; see https://pytorch.org/docs/stable/distributed.html\"\"\")\n","    parser.add_argument(\"--local_rank\", default=0, type=int, help=\"Please ignore and do not set this argument.\")\n","    parser.add_argument('--data_path', default='/path/to/imagenet/', type=str)\n","\n","    # Dataset\n","    parser.add_argument('--zip_mode', type=utils.bool_flag, default=False, help=\"\"\"Whether or not\n","        to use zip file.\"\"\")\n","\n","\n","    parser.add_argument('opts',\n","                        help=\"Modify config options using the command-line\",\n","                        default=None,\n","                        nargs=argparse.REMAINDER)    \n","\n","    args = parser.parse_args()\n","\n","    utils.init_distributed_mode(args)\n","    print(\"git:\\n  {}\\n\".format(utils.get_sha()))\n","    print(\"\\n\".join(\"%s: %s\" % (k, str(v)) for k, v in sorted(dict(vars(args)).items())))\n","    cudnn.benchmark = True\n","\n","    if args.load_features:\n","        train_features = torch.load(os.path.join(args.load_features, \"trainfeat.pth\"))\n","        test_features = torch.load(os.path.join(args.load_features, \"testfeat.pth\"))\n","        train_labels = torch.load(os.path.join(args.load_features, \"trainlabels.pth\"))\n","        test_labels = torch.load(os.path.join(args.load_features, \"testlabels.pth\"))\n","    else:\n","        # need to extract features !\n","        train_features, test_features, train_labels, test_labels = extract_feature_pipeline(args)\n","\n","    if utils.get_rank() == 0:\n","        if args.use_cuda:\n","            train_features = train_features.cuda()\n","            test_features = test_features.cuda()\n","            train_labels = train_labels.cuda()\n","            test_labels = test_labels.cuda()\n","\n","        print(\"Features are ready!\\nStart the k-NN classification.\")\n","\n","        log_stats = {}\n","        for k in args.nb_knn:\n","            top1, top5 = knn_classifier(train_features, train_labels,\n","                test_features, test_labels, k, args.temperature)\n","            print(f\"{k}-NN classifier result: Top1: {top1}, Top5: {top5}\")\n","            log_stats[k] = [top1, top5] \n","\n","        if utils.is_main_process():\n","            with (Path(args.dump_features) / \"log.txt\").open(\"a\") as f:\n","                f.write(json.dumps(log_stats) + \"\\n\")\n","    dist.barrier()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i0utDwbxTXON","executionInfo":{"status":"ok","timestamp":1649255094694,"user_tz":-270,"elapsed":356889,"user":{"displayName":"reza abbasi","userId":"16461171515024221393"}},"outputId":"74c739d7-59b9-4d86-aff1-4b836fc101d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n","and will be removed in future. Use torchrun.\n","Note that --use_env is set by default in torchrun.\n","If your script expects `--local_rank` argument to be set, please\n","change it to read from `os.environ['LOCAL_RANK']` instead. See \n","https://pytorch.org/docs/stable/distributed.html#launch-utility for \n","further instructions\n","\n","  FutureWarning,\n","| distributed init (rank 0): env://\n","fatal: not a git repository (or any parent up to mount point /content)\n","Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n","git:\n","  sha: N/A, status: clean, branch: N/A\n","\n","arch: swin_small\n","batch_size_per_gpu: 256\n","cfg: experiments/imagenet/swin/swin_small_patch4_window7_224.yaml\n","checkpoint_key: teacher\n","data_path: /content/drive/MyDrive/dataSets/CRC/forDINO\n","dist_url: env://\n","dump_features: features\n","gpu: 0\n","load_features: None\n","local_rank: 0\n","nb_knn: [10, 20, 100, 200]\n","num_workers: 10\n","opts: ['MODEL.NUM_CLASSES', '0']\n","patch_size: 4\n","pretrained_weights: /content/drive/MyDrive/models/esvit-main/test/checkpoint.pth\n","rank: 0\n","temperature: 0.07\n","use_cuda: True\n","world_size: 1\n","zip_mode: False\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Data loaded with 42742 train and 3000 val imgs.\n","=> merge config from experiments/imagenet/swin/swin_small_patch4_window7_224.yaml\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model swin_small 4x4 built.\n","Take key teacher in provided checkpoint dict\n","Pretrained weights found at /content/drive/MyDrive/models/esvit-main/test/checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n","Extracting features for train set...\n","Storing features into tensor of shape torch.Size([42742, 768])\n","  [  0/167]  eta: 2:08:14    time: 46.075741  data: 42.944805  max mem: 5794\n","  [ 10/167]  eta: 0:14:29    time: 5.539186  data: 3.906928  max mem: 5922\n","  [ 20/167]  eta: 0:08:48    time: 1.471746  data: 0.002365  max mem: 5922\n","  [ 30/167]  eta: 0:06:38    time: 1.459292  data: 0.002950  max mem: 5922\n","  [ 40/167]  eta: 0:05:26    time: 1.500103  data: 0.004430  max mem: 5922\n","  [ 50/167]  eta: 0:04:34    time: 1.486377  data: 0.004174  max mem: 5922\n","  [ 60/167]  eta: 0:03:56    time: 1.458945  data: 0.003067  max mem: 5922\n","  [ 70/167]  eta: 0:03:23    time: 1.441848  data: 0.002665  max mem: 5922\n","  [ 80/167]  eta: 0:02:55    time: 1.424034  data: 0.002144  max mem: 5922\n","  [ 90/167]  eta: 0:02:30    time: 1.445864  data: 0.001139  max mem: 5922\n","  [100/167]  eta: 0:02:07    time: 1.427740  data: 0.008097  max mem: 5922\n","  [110/167]  eta: 0:01:45    time: 1.408687  data: 0.009912  max mem: 5922\n","  [120/167]  eta: 0:01:25    time: 1.402123  data: 0.003591  max mem: 5922\n","  [130/167]  eta: 0:01:06    time: 1.406886  data: 0.002620  max mem: 5922\n","  [140/167]  eta: 0:00:47    time: 1.420728  data: 0.002585  max mem: 5922\n","  [150/167]  eta: 0:00:29    time: 1.428295  data: 0.002693  max mem: 5922\n","  [160/167]  eta: 0:00:11    time: 1.362736  data: 0.001508  max mem: 5922\n","  [166/167]  eta: 0:00:01    time: 1.313158  data: 0.000184  max mem: 5922\n"," Total time: 0:04:43 (1.698501 s / it)\n","Extracting features for val set...\n","Storing features into tensor of shape torch.Size([3000, 768])\n","  [ 0/12]  eta: 0:03:04    time: 15.335217  data: 14.016234  max mem: 5922\n","  [10/12]  eta: 0:00:05    time: 2.562799  data: 1.274354  max mem: 5931\n","  [11/12]  eta: 0:00:02    time: 2.436432  data: 1.168165  max mem: 5931\n"," Total time: 0:00:29 (2.460192 s / it)\n","Features are ready!\n","Start the k-NN classification.\n","10-NN classifier result: Top1: 28.166666666666668, Top5: 51.833333333333336\n","20-NN classifier result: Top1: 28.3, Top5: 61.13333333333333\n","100-NN classifier result: Top1: 28.4, Top5: 84.4\n","200-NN classifier result: Top1: 28.766666666666666, Top5: 93.06666666666666\n"]}],"source":["!python -m torch.distributed.launch  eval_knn.py --data_path /content/drive/MyDrive/dataSets/CRC/forDINO --dump_features features --pretrained_weights /content/drive/MyDrive/models/esvit-main/test/checkpoint.pth --checkpoint_key teacher --batch_size_per_gpu 256 --arch swin_small --cfg experiments/imagenet/swin/swin_small_patch4_window7_224.yaml MODEL.NUM_CLASSES 0"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9rwbISRJ2XNw","outputId":"643232ee-c55b-4f8b-c2ac-5e4313998745","executionInfo":{"status":"ok","timestamp":1649228665168,"user_tz":-270,"elapsed":366523,"user":{"displayName":"reza abbasi","userId":"16461171515024221393"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n","and will be removed in future. Use torchrun.\n","Note that --use_env is set by default in torchrun.\n","If your script expects `--local_rank` argument to be set, please\n","change it to read from `os.environ['LOCAL_RANK']` instead. See \n","https://pytorch.org/docs/stable/distributed.html#launch-utility for \n","further instructions\n","\n","  FutureWarning,\n","| distributed init (rank 0): env://\n","fatal: not a git repository (or any parent up to mount point /content)\n","Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n","git:\n","  sha: N/A, status: clean, branch: N/A\n","\n","arch: swin_small\n","batch_size_per_gpu: 256\n","cfg: experiments/imagenet/swin/swin_small_patch4_window14_224.yaml\n","checkpoint_key: teacher\n","data_path: /content/drive/MyDrive/dataSets/CRC/forDINO\n","dist_url: env://\n","dump_features: features\n","gpu: 0\n","load_features: None\n","local_rank: 0\n","nb_knn: [10, 20, 100, 200]\n","num_workers: 10\n","opts: ['MODEL.NUM_CLASSES', '0']\n","patch_size: 8\n","pretrained_weights: /content/drive/MyDrive/models/esvit-main/test/checkpoint.pth\n","rank: 0\n","temperature: 0.07\n","use_cuda: True\n","world_size: 1\n","zip_mode: False\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Data loaded with 42742 train and 3000 val imgs.\n","=> merge config from experiments/imagenet/swin/swin_small_patch4_window14_224.yaml\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model swin_small 8x8 built.\n","Take key teacher in provided checkpoint dict\n","Pretrained weights found at /content/drive/MyDrive/models/esvit-main/test/checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head_dense.mlp.0.weight', 'head_dense.mlp.0.bias', 'head_dense.mlp.2.weight', 'head_dense.mlp.2.bias', 'head_dense.mlp.4.weight', 'head_dense.mlp.4.bias', 'head_dense.last_layer.weight_g', 'head_dense.last_layer.weight_v', 'head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n","Extracting features for train set...\n","Storing features into tensor of shape torch.Size([42742, 768])\n","  [  0/167]  eta: 2:03:08    time: 44.243431  data: 40.012901  max mem: 8541\n","  [ 10/167]  eta: 0:14:05    time: 5.385770  data: 3.640127  max mem: 8669\n","  [ 20/167]  eta: 0:08:52    time: 1.590197  data: 0.002789  max mem: 8669\n","  [ 30/167]  eta: 0:06:44    time: 1.609500  data: 0.002012  max mem: 8669\n","  [ 40/167]  eta: 0:05:29    time: 1.517963  data: 0.001371  max mem: 8669\n","  [ 50/167]  eta: 0:04:38    time: 1.503412  data: 0.002643  max mem: 8669\n","  [ 60/167]  eta: 0:03:59    time: 1.514821  data: 0.002360  max mem: 8669\n","  [ 70/167]  eta: 0:03:27    time: 1.508829  data: 0.001536  max mem: 8669\n","  [ 80/167]  eta: 0:02:59    time: 1.504192  data: 0.001541  max mem: 8669\n","  [ 90/167]  eta: 0:02:33    time: 1.504782  data: 0.001543  max mem: 8669\n","  [100/167]  eta: 0:02:10    time: 1.503525  data: 0.001937  max mem: 8669\n","  [110/167]  eta: 0:01:48    time: 1.503100  data: 0.002612  max mem: 8669\n","  [120/167]  eta: 0:01:28    time: 1.497536  data: 0.002552  max mem: 8669\n","  [130/167]  eta: 0:01:08    time: 1.499190  data: 0.002186  max mem: 8669\n","  [140/167]  eta: 0:00:49    time: 1.501256  data: 0.002482  max mem: 8669\n","  [150/167]  eta: 0:00:30    time: 1.499974  data: 0.002742  max mem: 8669\n","  [160/167]  eta: 0:00:12    time: 1.494067  data: 0.001730  max mem: 8669\n","  [166/167]  eta: 0:00:01    time: 1.492106  data: 0.000137  max mem: 8669\n"," Total time: 0:04:56 (1.774474 s / it)\n","Extracting features for val set...\n","Storing features into tensor of shape torch.Size([3000, 768])\n","  [ 0/12]  eta: 0:03:12    time: 16.034781  data: 14.313437  max mem: 8669\n","  [10/12]  eta: 0:00:05    time: 2.723544  data: 1.301326  max mem: 8678\n","  [11/12]  eta: 0:00:02    time: 2.619229  data: 1.192889  max mem: 8678\n"," Total time: 0:00:31 (2.643695 s / it)\n","Features are ready!\n","Start the k-NN classification.\n","10-NN classifier result: Top1: 28.733333333333334, Top5: 53.0\n","20-NN classifier result: Top1: 29.0, Top5: 60.766666666666666\n","100-NN classifier result: Top1: 29.066666666666666, Top5: 82.03333333333333\n","200-NN classifier result: Top1: 29.4, Top5: 90.5\n"]}],"source":["!python -m torch.distributed.launch  eval_knn.py --data_path /content/drive/MyDrive/dataSets/CRC/forDINO --dump_features features --pretrained_weights /content/drive/MyDrive/models/esvit-main/test/checkpoint.pth --checkpoint_key teacher --batch_size_per_gpu 256 --arch swin_small --cfg experiments/imagenet/swin/swin_small_patch4_window14_224.yaml MODEL.NUM_CLASSES 0"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"test swin.ipynb","provenance":[],"authorship_tag":"ABX9TyOFNQxSLvo8hE3xSSwNQrNi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}